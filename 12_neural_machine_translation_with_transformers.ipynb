{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Phobj8HIsWpy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import sklearn### machine learning library\n",
        "import cv2## image processing\n",
        "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
        "import seaborn as sns### visualizations\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from numpy import random\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,LayerNormalization,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input,MultiHeadAttention,Embedding,TextVectorization)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from tensorboard.plugins import projector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation"
      ],
      "metadata": {
        "id": "5i9M0sp35GaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Download"
      ],
      "metadata": {
        "id": "KcPGqJtB5geB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UTPkaeJ5iWu",
        "outputId": "5b094bf6-ac79-43aa-e9aa-fd886d58e70c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-23 23:53:50--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7757635 (7.4M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.40M  19.0MB/s    in 0.4s    \n",
            "\n",
            "2023-11-23 23:53:50 (19.0 MB/s) - ‘fra-eng.zip’ saved [7757635/7757635]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QK4FI785ju4",
        "outputId": "5ec52686-4883-4b48-bb99-91e53c2d3cf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "DC7-4OAN5lcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_dataset=tf.data.TextLineDataset(\"/content/dataset/fra.txt\")"
      ],
      "metadata": {
        "id": "p3LuOOoB5m32"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE=20000\n",
        "ENGLISH_SEQUENCE_LENGTH=32\n",
        "FRENCH_SEQUENCE_LENGTH=32\n",
        "EMBEDDING_DIM=256\n",
        "BATCH_SIZE=128"
      ],
      "metadata": {
        "id": "EV_Afd4e5ovi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "Ja6Bk-l-5qvA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_vectorize_layer=TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "6T81avCx5sTZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selector(input_text):\n",
        "  split_text=tf.strings.split(input_text,'\\t')\n",
        "  return {'input_1':split_text[0:1],'input_2':'starttoken '+split_text[1:2]},split_text[1:2]+' endtoken'"
      ],
      "metadata": {
        "id": "WhusfADg5tj3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset=text_dataset.map(selector)"
      ],
      "metadata": {
        "id": "Rc_RXYct5vZA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separator(input_text):\n",
        "  split_text=tf.strings.split(input_text,'\\t')\n",
        "  return split_text[0:1],'starttoken '+split_text[1:2]+' endtoken'"
      ],
      "metadata": {
        "id": "Dv1No-Wi5wY3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_dataset=text_dataset.map(separator)"
      ],
      "metadata": {
        "id": "YLein0rY5xXf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85uOyUft5ylh",
        "outputId": "90eff352-24ef-4315-8326-d7f1b9d39038"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_training_data=init_dataset.map(lambda x,y:x)### input x,y and output x\n",
        "english_vectorize_layer.adapt(english_training_data)#### adapt the vectorize_layer to the training data"
      ],
      "metadata": {
        "id": "aTF-7Nuj50M-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_training_data=init_dataset.map(lambda x,y:y)### input x,y and output y\n",
        "french_vectorize_layer.adapt(french_training_data)#### adapt the vectorize_layer to the training data"
      ],
      "metadata": {
        "id": "DkkNfagC51lF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorizer(inputs,output):\n",
        "  return {'input_1':english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2':french_vectorize_layer(inputs['input_2'])},french_vectorize_layer(output)"
      ],
      "metadata": {
        "id": "opKszJRK526o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J81TU3b-520Y",
        "outputId": "699fa3ab-425a-4828-8fb6-a3cf44fdb8f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=split_dataset.map(vectorizer)"
      ],
      "metadata": {
        "id": "Z7zO9HHi55F0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWD6uCiT56hI",
        "outputId": "4b7ae254-9d05-476e-80a9-7f2f8f46f507"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiEej9Av58J7",
        "outputId": "ba455256-06ba-4711-dcff-a3719fce308b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[  2, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[103,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0]])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov9yBV_Y59PU",
        "outputId": "74536242-0e19-409f-df91-a5599bea80e1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None, 32), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 32), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 32), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "7pO36ULi5-vu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_K1FGFp6AFD",
        "outputId": "68974c45-e527-4f3d-db3b-9230c5a7ef64"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, 32), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 32), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 32), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_BATCHES=int(200000/BATCH_SIZE)"
      ],
      "metadata": {
        "id": "6wa0kwrO6BSN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"
      ],
      "metadata": {
        "id": "61g48rmj6Cse"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOI4HttT6EGk",
        "outputId": "a700ba0b-f04f-46b0-a7d8-03ec24e0cf8d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_1': TensorSpec(shape=(None, 32), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 32), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 32), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#score=tf.einsum('ijk,ibk->ijb',query,key)"
      ],
      "metadata": {
        "id": "7y2Ojo9H6G5O"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "gPIoK7nc6Lie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding"
      ],
      "metadata": {
        "id": "VhwgcA5o6NAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(model_size,SEQUENCE_LENGTH):\n",
        "  output=[]\n",
        "  for pos in range(SEQUENCE_LENGTH):\n",
        "    PE=np.zeros((model_size))\n",
        "    for i in range(model_size):\n",
        "      if i%2==0:\n",
        "        PE[i]=np.sin(pos/(10000**(i/model_size)))\n",
        "      else:\n",
        "        PE[i]=np.cos(pos/(10000**((i-1)/model_size)))\n",
        "    output.append(tf.expand_dims(PE,axis=0))\n",
        "  out=tf.concat(output,axis=0)\n",
        "  out=tf.expand_dims(out,axis=0)\n",
        "  return tf.cast(out,dtype=tf.float32)"
      ],
      "metadata": {
        "id": "Fz7bcCtD6OvA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(positional_encoding(256,64).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VvO6VraCrcY",
        "outputId": "7c689329-5231-4d0d-f4ec-552fc5a47cda"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 64, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(Layer):\n",
        "  def __init__(self, sequence_length, vocab_size, embed_dim,):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.token_embeddings=Embedding(\n",
        "        input_dim=vocab_size, output_dim=embed_dim)\n",
        "    self.sequence_length = sequence_length\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedded_tokens = self.token_embeddings(inputs)\n",
        "    embedded_positions=positional_encoding(\n",
        "        self.embed_dim,self.sequence_length)\n",
        "    return embedded_tokens + embedded_positions\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    return tf.math.not_equal(inputs, 0)"
      ],
      "metadata": {
        "id": "piTU-FSIBXF0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input=tf.constant([[2,112,10,12,5,0,0,0,]])\n",
        "emb=Embeddings(8,20000,256)\n",
        "emb_out=emb(test_input)\n",
        "print(emb_out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g99A4hZ4D9-b",
        "outputId": "5a60acaa-4f1d-4ace-89a4-65a54729e24e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 8, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = emb.compute_mask(test_input)\n",
        "mask1 = mask[:, :, tf.newaxis]\n",
        "mask2 = mask[:, tf.newaxis, :]\n",
        "padding_mask = tf.cast(mask1&mask2, dtype=\"int32\")\n",
        "print(padding_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy61632pITbV",
        "outputId": "825f792e-c578-461c-b648-f106d18dfde7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0]]], shape=(1, 8, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom MultiHeadAttention"
      ],
      "metadata": {
        "id": "pROfzh_Ft28I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSelfAttention(Layer):\n",
        "  def __init__(self, model_size):\n",
        "    super(CustomSelfAttention, self).__init__()\n",
        "    self.model_size=model_size\n",
        "  def call(self, query, key, value, masking):\n",
        "    ########### Compute scores\n",
        "    score = tf.matmul(query, key, transpose_b=True)\n",
        "    ########### scaling\n",
        "    score/=tf.math.sqrt(tf.cast(self.model_size, tf.float32))\n",
        "    ########### masking\n",
        "    masking=tf.cast(masking, dtype=tf.float32)\n",
        "    score+=(1.-masking)*-1e10\n",
        "    ########### atttention_weights\n",
        "    attention=tf.nn.softmax(score, axis=-1)*masking\n",
        "    ########### output\n",
        "    head=tf.matmul(attention, value)\n",
        "    return head"
      ],
      "metadata": {
        "id": "E2Bf9iPVt3Wo"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention=CustomSelfAttention(256)\n",
        "attention(tf.ones([1,8,256]), tf.ones([1,8,256]), tf.ones([1,8,256]), padding_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcdAE17kwc4A",
        "outputId": "dab7011b-bb7f-482f-f8ec-0c3bbc2086c4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8, 256), dtype=float32, numpy=\n",
              "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        [1., 1., 1., ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMultiHeadAttention(Layer):\n",
        "  def __init__(self, num_heads, key_dim):\n",
        "    super(CustomMultiHeadAttention, self).__init__()\n",
        "\n",
        "    self.num_heads=num_heads\n",
        "    self.dense_q=[Dense(key_dim) for _ in range(num_heads)]\n",
        "    self.dense_k=[Dense(key_dim) for _ in range(num_heads)]\n",
        "    self.dense_v=[Dense(key_dim) for _ in range(num_heads)]\n",
        "    self.dense_o=Dense(key_dim)\n",
        "    self.self_attention=CustomSelfAttention(key_dim)\n",
        "\n",
        "  def call(self, query, key, value, attention_mask):\n",
        "    heads=[]\n",
        "\n",
        "    for i in range(self.num_heads):\n",
        "      head=self.self_attention(self.dense_q[i](query), self.dense_k[i](key),\n",
        "                               self.dense_v[i](value), attention_mask)\n",
        "      heads.append(head)\n",
        "    heads=tf.concat(heads, axis=2)\n",
        "    heads=self.dense_o(heads)\n",
        "    return heads"
      ],
      "metadata": {
        "id": "6qZ_nZklz5FO"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "x2onT5luEr--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(Layer):\n",
        "  def __init__(self, embed_dim, dense_dim, num_heads,):\n",
        "    super(TransformerEncoder, self).__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.dense_dim = dense_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.attention = CustomMultiHeadAttention(\n",
        "        num_heads = num_heads, key_dim=embed_dim,\n",
        "    )\n",
        "    self.dense_proj=tf.keras.Sequential(\n",
        "        [Dense(dense_dim, activation=\"relu\"),\n",
        "         Dense(embed_dim),]\n",
        "    )\n",
        "    self.layernorm_1 = LayerNormalization()\n",
        "    self.layernorm_2 = LayerNormalization()\n",
        "    self.supports_masking = True\n",
        "\n",
        "  def call(self, inputs, mask=None):\n",
        "    print(mask)\n",
        "    if mask is not None:\n",
        "      mask = tf.cast(\n",
        "          mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "      T=tf.shape(mask)[2]\n",
        "      padding_mask = tf.repeat(mask, T, axis=1)\n",
        "      print(padding_mask)\n",
        "    attention_output = self.attention(\n",
        "        query=inputs, key=inputs, value=inputs,\n",
        "        attention_mask=padding_mask\n",
        "    )\n",
        "\n",
        "    proj_input = self.layernorm_1(inputs + attention_output)\n",
        "    proj_output = self.dense_proj(proj_input)\n",
        "    return self.layernorm_2(proj_input + proj_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "PGCmQBC7E_Qk"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_outputs = TransformerEncoder(256, 2048, 2)(emb_out)\n",
        "print(encoder_outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cDgcMkIGqT7",
        "outputId": "1fc32cd7-4084-4208-eedf-cbf204642600"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ True  True  True  True  True False False False]], shape=(1, 8), dtype=bool)\n",
            "tf.Tensor(\n",
            "[[[1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]]], shape=(1, 8, 8), dtype=int32)\n",
            "(1, 8, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "gN_MgJKrOURN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.linalg.band_part(\n",
        "    tf.ones([1, 8, 8], dtype=tf.int32), -1,0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtzmv3YNRMKx",
        "outputId": "976b6186-cdd5-4ff7-c42b-222b173e047e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1 0 0 0 0 0 0 0]\n",
            "  [1 1 0 0 0 0 0 0]\n",
            "  [1 1 1 0 0 0 0 0]\n",
            "  [1 1 1 1 0 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 1 0]\n",
            "  [1 1 1 1 1 1 1 1]]], shape=(1, 8, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(Layer):\n",
        "  def __init__(self, embed_dim, latent_dim, num_heads):\n",
        "    super(TransformerDecoder, self).__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.attention_1 = CustomMultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embed_dim\n",
        "    )\n",
        "    self.attention_2 = CustomMultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=embed_dim\n",
        "    )\n",
        "    self.dense_proj = tf.keras.Sequential(\n",
        "        [Dense(latent_dim, activation=\"relu\"), Dense(embed_dim),]\n",
        "    )\n",
        "    self.layernorm_1=LayerNormalization()\n",
        "    self.layernorm_2=LayerNormalization()\n",
        "    self.layernorm_3=LayerNormalization()\n",
        "    self.supports_masking = True\n",
        "  def call(self, inputs, encoder_outputs, enc_mask, mask=None):\n",
        "\n",
        "    if mask is not None:\n",
        "      causal_mask=tf.linalg.band_part(\n",
        "          tf.ones([tf.shape(inputs)[0],\n",
        "                   tf.shape(inputs)[1],\n",
        "                   tf.shape(inputs)[1]], dtype=tf.int32), -1, 0)\n",
        "      mask = tf.cast(\n",
        "          mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "      enc_mask = tf.cast(\n",
        "          enc_mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "\n",
        "      T = tf.shape(mask)[2]\n",
        "      padding_mask = tf.repeat(mask, T, axis=1)\n",
        "      cross_attn_mask = tf.repeat(enc_mask, T, axis=1)\n",
        "      combined_mask = tf.minimum(padding_mask, causal_mask)\n",
        "      # print('padding', padding_mask)\n",
        "      # print('causal', causal_mask)\n",
        "      # print('crossattnmask', cross_attn_mask)\n",
        "      # print('combinedmask', combined_mask)\n",
        "    attention_output_1 = self.attention_1(\n",
        "        query=inputs, key=inputs, value=inputs,\n",
        "        attention_mask=combined_mask,\n",
        "    )\n",
        "\n",
        "    out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "    attention_output_2, scores= self.attention_2(\n",
        "        query=out_1,key=encoder_outputs,value=encoder_outputs,\n",
        "        attention_mask=cross_attn_mask,\n",
        "        return_attention_scores=True\n",
        "\n",
        "    )\n",
        "    out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "    proj_output = self.dense_proj(out_2)\n",
        "    return self.layernorm_3(out_2 + proj_output), scores"
      ],
      "metadata": {
        "id": "Sycx3luUOUyz"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_mask=mask\n",
        "decoder_outputs, scores = TransformerDecoder(256,2048,4)(emb_out,encoder_outputs,enc_mask)\n",
        "print(decoder_outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqzoGhqwUT9r",
        "outputId": "23ca4e02-fc66-41ca-fa24-55697e9f507d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padding tf.Tensor(\n",
            "[[[1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]]], shape=(1, 8, 8), dtype=int32)\n",
            "causal tf.Tensor(\n",
            "[[[1 0 0 0 0 0 0 0]\n",
            "  [1 1 0 0 0 0 0 0]\n",
            "  [1 1 1 0 0 0 0 0]\n",
            "  [1 1 1 1 0 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 1 0 0]\n",
            "  [1 1 1 1 1 1 1 0]\n",
            "  [1 1 1 1 1 1 1 1]]], shape=(1, 8, 8), dtype=int32)\n",
            "crossattnmask tf.Tensor(\n",
            "[[[1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]]], shape=(1, 8, 8), dtype=int32)\n",
            "combinedmask tf.Tensor(\n",
            "[[[1 0 0 0 0 0 0 0]\n",
            "  [1 1 0 0 0 0 0 0]\n",
            "  [1 1 1 0 0 0 0 0]\n",
            "  [1 1 1 1 0 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]\n",
            "  [1 1 1 1 1 0 0 0]]], shape=(1, 8, 8), dtype=int32)\n",
            "(1, 8, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Model"
      ],
      "metadata": {
        "id": "kqRrvjJ-XdXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM=128\n",
        "D_FF=1024\n",
        "NUM_HEADS=8\n",
        "NUM_LAYERS=1\n",
        "NUM_EPOCHS=20"
      ],
      "metadata": {
        "id": "L384YXygXh3p"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_1\")\n",
        "emb = Embeddings(ENGLISH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)\n",
        "x = emb(encoder_inputs)\n",
        "enc_mask = emb.compute_mask(encoder_inputs)\n",
        "\n",
        "for _ in range(NUM_LAYERS):\n",
        "  x=TransformerEncoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x)\n",
        "encoder_outputs=x\n",
        "\n",
        "decoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_2\")\n",
        "\n",
        "x = Embeddings(FRENCH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(decoder_inputs)\n",
        "for i in range(NUM_LAYERS):\n",
        "  x=TransformerDecoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x, encoder_outputs,enc_mask)\n",
        "x=tf.keras.layers.Dropout(0.5)(x)\n",
        "decoder_outputs=Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "\n",
        "attention_score_model = tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], attention_scores, name=\"transformer\"\n",
        ")\n",
        "\n",
        "transformer = tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")\n",
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHshdDYBXlFV",
        "outputId": "3f632e60-35a2-45ef-f995-acd26917a49b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"Placeholder_1:0\", shape=(None, None), dtype=bool)\n",
            "Tensor(\"transformer_encoder_12/Repeat/Reshape_1:0\", shape=(None, None, None), dtype=int32)\n",
            "padding Tensor(\"transformer_decoder_9/Repeat/Reshape_1:0\", shape=(None, None, None), dtype=int32)\n",
            "causal Tensor(\"transformer_decoder_9/MatrixBandPart:0\", shape=(None, 32, 32), dtype=int32)\n",
            "crossattnmask Tensor(\"transformer_decoder_9/Repeat_1/Reshape_1:0\", shape=(None, None, None), dtype=int32)\n",
            "combinedmask Tensor(\"transformer_decoder_9/Minimum:0\", shape=(None, 32, 32), dtype=int32)\n",
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embeddings_8 (Embeddings)   (None, 32, 128)              2560000   ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embeddings_9 (Embeddings)   (None, 32, 128)              2560000   ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " transformer_encoder_12 (Tr  (None, 32, 128)              791296    ['embeddings_8[0][0]']        \n",
            " ansformerEncoder)                                                                                \n",
            "                                                                                                  \n",
            " tf.math.not_equal_3 (TFOpL  (None, None)                 0         ['input_1[0][0]']             \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " transformer_decoder_9 (Tra  (None, 32, 128)              1319040   ['embeddings_9[0][0]',        \n",
            " nsformerDecoder)                                                    'transformer_encoder_12[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'tf.math.not_equal_3[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 32, 128)              0         ['transformer_decoder_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_586 (Dense)           (None, 32, 20000)            2580000   ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9810336 (37.42 MB)\n",
            "Trainable params: 9810336 (37.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "t6tcjf4VaFnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BLEU(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='bleu_score'):\n",
        "        super(BLEU,self).__init__()\n",
        "        self.bleu_score=0\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "      y_pred=tf.argmax(y_pred,-1)\n",
        "      self.bleu_score=0\n",
        "      for i,j in zip(y_pred,y_true):\n",
        "        tf.autograph.experimental.set_loop_options()\n",
        "\n",
        "        total_words=tf.math.count_nonzero(i)\n",
        "        total_matches=0\n",
        "        for word in i:\n",
        "          if word==0:\n",
        "            break\n",
        "          for q in range(len(j)):\n",
        "            if j[q]==0:\n",
        "              break\n",
        "            if word==j[q]:\n",
        "              total_matches+=1\n",
        "              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
        "              break\n",
        "\n",
        "        self.bleu_score+=total_matches/total_words\n",
        "\n",
        "    def result(self):\n",
        "        return self.bleu_score/BATCH_SIZE"
      ],
      "metadata": {
        "id": "ag1Aaz0VaLVF"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Scheduler(LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps):\n",
        "    super(Scheduler, self).__init__()\n",
        "    self.d_model = tf.cast(d_model, tf.float64)\n",
        "    self.warmup_steps = tf.cast(warmup_steps, dtype=tf.float64)\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float64)\n",
        "    return (self.d_model**(-0.5))*tf.math.minimum(step**(-0.5), step * (self.warmup_steps ** -1.5))"
      ],
      "metadata": {
        "id": "kwyX4L-HaGlQ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WARM_UP_STEPS = 4000\n",
        "lr_scheduled = Scheduler(EMBEDDING_DIM, WARM_UP_STEPS)"
      ],
      "metadata": {
        "id": "CAmBUlO8aNbS"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = Adam(lr_scheduled, beta_1=0.9, beta_2=0.98, epsilon=1e-9),)\n",
        "    #metrics=[BLEU()],\n",
        "    #run_eagerly=True)"
      ],
      "metadata": {
        "id": "ozEOSfBqaOX-"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=transformer.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tminpPd9aPTY",
        "outputId": "3cef1bec-7607-4719-b9e1-e34f3c4b4ce2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Tensor(\"transformer/embeddings_8/NotEqual:0\", shape=(None, 32), dtype=bool)\n",
            "Tensor(\"transformer/transformer_encoder_12/Repeat/Reshape_1:0\", shape=(None, 32, 32), dtype=int32)\n",
            "padding Tensor(\"transformer/transformer_decoder_9/Repeat/Reshape_1:0\", shape=(None, 32, 32), dtype=int32)\n",
            "causal Tensor(\"transformer/transformer_decoder_9/MatrixBandPart:0\", shape=(None, 32, 32), dtype=int32)\n",
            "crossattnmask Tensor(\"transformer/transformer_decoder_9/Repeat_1/Reshape_1:0\", shape=(None, 32, 32), dtype=int32)\n",
            "combinedmask Tensor(\"transformer/transformer_decoder_9/Minimum:0\", shape=(None, 32, 32), dtype=int32)\n",
            "Tensor(\"transformer/embeddings_8/NotEqual:0\", shape=(None, 32), dtype=bool)\n",
            "Tensor(\"transformer/transformer_encoder_12/Repeat/Reshape_1:0\", shape=(None, 32, 32), dtype=int32)\n",
            "padding Tensor(\"transformer/transformer_decoder_9/Repeat/Reshape_1:0\", shape=(None, 32, 32), dtype=int32)\n",
            "causal Tensor(\"transformer/transformer_decoder_9/MatrixBandPart:0\", shape=(None, 32, 32), dtype=int32)\n",
            "crossattnmask Tensor(\"transformer/transformer_decoder_9/Repeat_1/Reshape_1:0\", shape=(None, 32, 32), dtype=int32)\n",
            "combinedmask Tensor(\"transformer/transformer_decoder_9/Minimum:0\", shape=(None, 32, 32), dtype=int32)\n",
            "   1405/Unknown - 218s 133ms/step - loss: 6.1301Tensor(\"transformer/embeddings_8/NotEqual:0\", shape=(None, 32), dtype=bool)\n",
            "Tensor(\"transformer/transformer_encoder_12/Repeat/Reshape_1:0\", shape=(None, 32, 32), dtype=int32)\n",
            "padding Tensor(\"transformer/transformer_decoder_9/Repeat/Reshape_1:0\", shape=(None, 32, 32), dtype=int32)\n",
            "causal Tensor(\"transformer/transformer_decoder_9/MatrixBandPart:0\", shape=(None, 32, 32), dtype=int32)\n",
            "crossattnmask Tensor(\"transformer/transformer_decoder_9/Repeat_1/Reshape_1:0\", shape=(None, 32, 32), dtype=int32)\n",
            "combinedmask Tensor(\"transformer/transformer_decoder_9/Minimum:0\", shape=(None, 32, 32), dtype=int32)\n",
            "1405/1405 [==============================] - 268s 168ms/step - loss: 6.1301 - val_loss: 4.9676\n",
            "Epoch 2/10\n",
            "1405/1405 [==============================] - 213s 151ms/step - loss: 3.5370 - val_loss: 3.7612\n",
            "Epoch 3/10\n",
            "1405/1405 [==============================] - 221s 157ms/step - loss: 2.6723 - val_loss: 3.2986\n",
            "Epoch 4/10\n",
            "1405/1405 [==============================] - 183s 130ms/step - loss: 2.2306 - val_loss: 3.0123\n",
            "Epoch 5/10\n",
            "1405/1405 [==============================] - 176s 125ms/step - loss: 2.0043 - val_loss: 2.8585\n",
            "Epoch 6/10\n",
            "1405/1405 [==============================] - 174s 124ms/step - loss: 1.8731 - val_loss: 2.8169\n",
            "Epoch 7/10\n",
            "1405/1405 [==============================] - 184s 131ms/step - loss: 1.7885 - val_loss: 2.8652\n",
            "Epoch 8/10\n",
            "1405/1405 [==============================] - 175s 124ms/step - loss: 1.7263 - val_loss: 2.7896\n",
            "Epoch 9/10\n",
            "1405/1405 [==============================] - 175s 124ms/step - loss: 1.6778 - val_loss: 2.7894\n",
            "Epoch 10/10\n",
            "1405/1405 [==============================] - 175s 124ms/step - loss: 1.6373 - val_loss: 2.8170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save_weights('/content/drive/MyDrive/transformers.h5')"
      ],
      "metadata": {
        "id": "RpLstSHth5Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9yZhFkXdiLJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.evaluate(val_dataset)"
      ],
      "metadata": {
        "id": "HJYQ0IjPiMHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "_VcYWnwziPur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word={x:y for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                   french_vectorize_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "RJPMKfk9iSM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translator(english_sentence):\n",
        "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
        "  shifted_target='starttoken'\n",
        "\n",
        "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
        "    tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
        "    output=transformer.predict([tokenized_english_sentence,tokenized_shifted_target])\n",
        "    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n",
        "    current_word=index_to_word[french_word_index]\n",
        "    if current_word=='endtoken':\n",
        "      break\n",
        "    shifted_target+=' '+current_word\n",
        "  return shifted_target[11:]"
      ],
      "metadata": {
        "id": "hsLkXiW-iUSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator('What makes you think that it is not true?')"
      ],
      "metadata": {
        "id": "XbeOMQ18iWq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "CNUQepg48Agq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "60OYWC5n8BF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(english_sentence):\n",
        "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
        "  shifted_target='starttoken je lai fait très bien'\n",
        "\n",
        "  tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
        "  attention_weights=attention_score_model.predict([tokenized_english_sentence,\n",
        "                                                   tokenized_shifted_target])\n",
        "\n",
        "  return attention_weights\n",
        "\n",
        "out=visualize('I did it very well')\n"
      ],
      "metadata": {
        "id": "5YZA4pq78C5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out['decoder_layer1_block2'][0].shape)"
      ],
      "metadata": {
        "id": "JDz568QN8ERe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12,12))\n",
        "\n",
        "for i in range(NUM_HEADS):\n",
        "  ax = plt.subplot(2,4, i+1)\n",
        "\n",
        "  plt.imshow(out['decoder_layer1_block2'][0][i][0:10,0:10])\n",
        "  plt.title(\"Attention Scores for head:->\"+str(i+1))"
      ],
      "metadata": {
        "id": "E8GFcw4e8FcP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}